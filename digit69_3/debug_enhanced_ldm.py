#!/usr/bin/env python3
"""
Debug Enhanced LDM loading issues
"""

import torch
import pickle

def debug_enhanced_ldm_checkpoint():
    """Debug Enhanced LDM checkpoint structure"""
    print("ğŸ” DEBUGGING ENHANCED LDM CHECKPOINT")
    print("=" * 50)
    
    # Load checkpoint
    print("ğŸ“‚ Loading Enhanced LDM checkpoint...")
    checkpoint = torch.load('enhanced_ldm_best.pth', map_location='cpu')
    
    print(f"ğŸ“Š Checkpoint type: {type(checkpoint)}")
    
    if isinstance(checkpoint, dict):
        print(f"ğŸ“‹ Checkpoint keys: {list(checkpoint.keys())}")
        
        if 'model_state_dict' in checkpoint:
            model_state = checkpoint['model_state_dict']
            print(f"ğŸ“Š Model state dict type: {type(model_state)}")
            print(f"ğŸ“‹ Model state keys (first 10): {list(model_state.keys())[:10]}")
            print(f"ğŸ“Š Total model parameters: {len(model_state.keys())}")
            
            # Check for UNet prefix
            unet_keys = [k for k in model_state.keys() if k.startswith('unet.')]
            non_unet_keys = [k for k in model_state.keys() if not k.startswith('unet.')]
            
            print(f"ğŸ“Š UNet keys: {len(unet_keys)}")
            print(f"ğŸ“Š Non-UNet keys: {len(non_unet_keys)}")
            
            if unet_keys:
                print(f"ğŸ“‹ Sample UNet keys: {unet_keys[:5]}")
            if non_unet_keys:
                print(f"ğŸ“‹ Sample Non-UNet keys: {non_unet_keys[:5]}")
                
        # Check other checkpoint info
        for key, value in checkpoint.items():
            if key != 'model_state_dict':
                print(f"ğŸ“Š {key}: {type(value)} - {value if not torch.is_tensor(value) else f'Tensor {value.shape}'}")
    
    else:
        # Direct state dict
        print(f"ğŸ“‹ Direct state dict keys (first 10): {list(checkpoint.keys())[:10]}")
        print(f"ğŸ“Š Total parameters: {len(checkpoint.keys())}")

def test_enhanced_ldm_loading():
    """Test different loading approaches"""
    print("\nğŸ§ª TESTING ENHANCED LDM LOADING APPROACHES")
    print("=" * 50)
    
    from improved_unet import ImprovedUNet
    from enhanced_training_pipeline import EnhancedDiffusionModel
    
    # Create model
    print("ğŸ—ï¸ Creating Enhanced LDM model...")
    unet = ImprovedUNet(
        in_channels=1,
        out_channels=1,
        condition_dim=512,
        model_channels=64,
        num_res_blocks=2
    )
    
    model = EnhancedDiffusionModel(
        unet=unet,
        num_timesteps=1000
    )
    
    print(f"ğŸ“Š Model created successfully")
    print(f"ğŸ“Š Model parameters: {sum(p.numel() for p in model.parameters()):,}")
    
    # Test loading approaches
    checkpoint = torch.load('enhanced_ldm_best.pth', map_location='cpu')
    
    print("\nğŸ”§ Approach 1: Direct loading")
    try:
        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
            print("âœ… Approach 1 successful!")
        else:
            model.load_state_dict(checkpoint)
            print("âœ… Approach 1 successful!")
    except Exception as e:
        print(f"âŒ Approach 1 failed: {str(e)[:100]}...")
    
    print("\nğŸ”§ Approach 2: Remove 'unet.' prefix")
    try:
        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
        else:
            state_dict = checkpoint
            
        # Remove 'unet.' prefix if present
        new_state_dict = {}
        for key, value in state_dict.items():
            if key.startswith('unet.'):
                new_key = key[5:]  # Remove 'unet.' prefix
                new_state_dict[new_key] = value
            else:
                new_state_dict[key] = value
        
        model.unet.load_state_dict(new_state_dict)
        print("âœ… Approach 2 successful!")
    except Exception as e:
        print(f"âŒ Approach 2 failed: {str(e)[:100]}...")
    
    print("\nğŸ”§ Approach 3: Load only UNet part")
    try:
        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
        else:
            state_dict = checkpoint
            
        # Extract only UNet parameters
        unet_state_dict = {}
        for key, value in state_dict.items():
            if key.startswith('unet.'):
                new_key = key[5:]  # Remove 'unet.' prefix
                unet_state_dict[new_key] = value
        
        if unet_state_dict:
            model.unet.load_state_dict(unet_state_dict)
            print("âœ… Approach 3 successful!")
        else:
            print("âŒ Approach 3 failed: No UNet parameters found")
    except Exception as e:
        print(f"âŒ Approach 3 failed: {str(e)[:100]}...")

def test_enhanced_ldm_sampling():
    """Test Enhanced LDM sampling with device fixes"""
    print("\nğŸ¯ TESTING ENHANCED LDM SAMPLING")
    print("=" * 50)
    
    from improved_unet import ImprovedUNet
    from enhanced_training_pipeline import EnhancedDiffusionModel
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ“± Using device: {device}")
    
    # Create model
    unet = ImprovedUNet(
        in_channels=1,
        out_channels=1,
        condition_dim=512,
        model_channels=64,
        num_res_blocks=2
    )
    
    model = EnhancedDiffusionModel(
        unet=unet,
        num_timesteps=1000
    ).to(device)
    
    # Load checkpoint
    checkpoint = torch.load('enhanced_ldm_best.pth', map_location=device)
    
    try:
        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
        else:
            state_dict = checkpoint
            
        # Extract only UNet parameters and remove prefix
        unet_state_dict = {}
        for key, value in state_dict.items():
            if key.startswith('unet.'):
                new_key = key[5:]  # Remove 'unet.' prefix
                unet_state_dict[new_key] = value
        
        model.unet.load_state_dict(unet_state_dict)
        model.eval()
        print("âœ… Model loaded successfully!")
        
        # Test sampling
        print("ğŸ¯ Testing sampling...")
        test_condition = torch.randn(1, 512).to(device)
        
        with torch.no_grad():
            # Test with fewer timesteps first
            sample = model.sample(test_condition, image_size=28)
            print(f"âœ… Sampling successful! Output shape: {sample.shape}")
            print(f"ğŸ“Š Output range: [{sample.min():.3f}, {sample.max():.3f}]")
            
    except Exception as e:
        print(f"âŒ Sampling failed: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    debug_enhanced_ldm_checkpoint()
    test_enhanced_ldm_loading()
    test_enhanced_ldm_sampling()
