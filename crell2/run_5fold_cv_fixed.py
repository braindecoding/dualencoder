#!/usr/bin/env python3
"""
Run 5-Fold Cross-Validation with Fixed Validation Bug
Enhanced EEG Transformer with proper validation every epoch
"""

import sys
import os
from datetime import datetime
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import clip
import warnings
import time
import pickle
from sklearn.model_selection import StratifiedKFold
from collections import Counter
import random

warnings.filterwarnings("ignore")

# Add current directory to path
sys.path.append('.')

# Import our enhanced components
from enhanced_eeg_transformer import EnhancedEEGToEmbeddingModel
from data_augmentation import EEGAugmentation
from advanced_loss_functions import (
    AdaptiveTemperatureContrastiveLoss, 
    WarmupCosineScheduler
)

def set_random_seeds(seed=42):
    """Set random seeds for reproducibility"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    os.environ['PYTHONHASHSEED'] = str(seed)

def load_crell_data():
    """Load Crell dataset"""
    print("üìÇ Loading Crell dataset...")
    
    with open('../crell/crell_processed_data_correct.pkl', 'rb') as f:
        data = pickle.load(f)
    
    # Extract data
    eegTrn = data['training']['eeg']
    stimTrn = data['training']['images']
    labelsTrn = data['training']['labels']
    
    eegVal = data['validation']['eeg']
    stimVal = data['validation']['images'] if 'images' in data['validation'] else None
    labelsVal = data['validation']['labels']
    
    eegTest = data['test']['eeg']
    stimTest = data['test']['images'] if 'images' in data['test'] else None
    labelsTest = data['test']['labels']
    
    # For validation/test, use training images as reference
    if stimVal is None:
        label_to_image = {}
        for i, label in enumerate(labelsTrn):
            if label not in label_to_image:
                label_to_image[label] = stimTrn[i]
        
        stimVal = np.array([label_to_image[label] for label in labelsVal])
        stimTest = np.array([label_to_image[label] for label in labelsTest])
    
    print(f"‚úÖ Crell dataset loaded successfully!")
    print(f"   Training: {len(eegTrn)} samples")
    print(f"   Validation: {len(eegVal)} samples")
    print(f"   Test: {len(eegTest)} samples")
    
    return eegTrn, stimTrn, labelsTrn, eegVal, stimVal, labelsVal, eegTest, stimTest, labelsTest

def evaluate_crell(model, eeg_data, stim_data, labels, clip_model, clip_preprocess, device, phase_name, batch_size=32):
    """Evaluate model on Crell dataset"""
    model.eval()
    total_loss = 0
    total_accuracy = 0
    num_batches = 0
    
    with torch.no_grad():
        for i in range(0, len(eeg_data), batch_size):
            batch_eeg = eeg_data[i:i+batch_size]
            batch_stim = stim_data[i:i+batch_size]
            
            # Convert to tensors
            batch_eeg = torch.FloatTensor(batch_eeg).to(device)
            
            # Process images for CLIP
            processed_images = []
            for img in batch_stim:
                if isinstance(img, np.ndarray):
                    img = (img * 255).astype(np.uint8)
                    from PIL import Image
                    img = Image.fromarray(img).convert('RGB')
                processed_img = clip_preprocess(img).unsqueeze(0)
                processed_images.append(processed_img)
            processed_images = torch.cat(processed_images, dim=0).to(device)
            
            # Forward pass
            eeg_embeddings = model(batch_eeg)
            clip_embeddings = clip_model.encode_image(processed_images).float()
            
            # Normalize embeddings
            eeg_embeddings = nn.functional.normalize(eeg_embeddings, dim=1)
            clip_embeddings = nn.functional.normalize(clip_embeddings, dim=1)
            
            # Compute similarity and accuracy
            similarities = torch.cosine_similarity(eeg_embeddings, clip_embeddings, dim=1)
            accuracy = (similarities > 0.0).float().mean()
            
            # Simple loss (negative cosine similarity)
            loss = -similarities.mean()
            
            total_loss += loss.item()
            total_accuracy += accuracy.item()
            num_batches += 1
    
    avg_loss = total_loss / num_batches if num_batches > 0 else 0
    avg_accuracy = total_accuracy / num_batches if num_batches > 0 else 0
    
    return avg_loss, avg_accuracy

class Config:
    """Configuration for 5-fold CV"""
    def __init__(self):
        # Model architecture
        self.n_channels = 64
        self.seq_len = 500
        self.d_model = 256
        self.embedding_dim = 512
        self.nhead = 8
        self.num_layers = 8
        self.patch_size = 25
        self.dropout = 0.1
        
        # Training parameters (reduced for CV)
        self.num_epochs = 50  # Reduced for 5-fold CV
        self.batch_size = 32
        self.base_lr = 1e-4
        self.min_lr = 1e-6
        self.warmup_epochs = 10
        self.patience = 15  # Reduced patience
        self.weight_decay = 1e-4
        self.gradient_clip = 1.0
        
        # Loss function
        self.loss_type = 'adaptive_temperature'
        self.temperature = 0.05

def create_model(config, device):
    """Create enhanced EEG model"""
    model = EnhancedEEGToEmbeddingModel(
        n_channels=config.n_channels,
        seq_len=config.seq_len,
        d_model=config.d_model,
        embedding_dim=config.embedding_dim,
        nhead=config.nhead,
        num_layers=config.num_layers,
        patch_size=config.patch_size,
        dropout=config.dropout
    ).to(device)
    return model

def create_loss(config, device):
    """Create loss function"""
    return AdaptiveTemperatureContrastiveLoss(
        initial_temperature=config.temperature,
        learn_temperature=True
    ).to(device)

def create_optimizer_and_scheduler(model, config):
    """Create optimizer and scheduler"""
    optimizer = optim.AdamW(model.parameters(), lr=config.base_lr, weight_decay=config.weight_decay)
    scheduler = WarmupCosineScheduler(
        optimizer=optimizer,
        warmup_epochs=config.warmup_epochs,
        max_epochs=config.num_epochs,
        base_lr=config.base_lr,
        min_lr=config.min_lr
    )
    return optimizer, scheduler

def run_5fold_cv():
    """Run 5-fold cross-validation"""
    print("üîÑ 5-FOLD CROSS-VALIDATION - FIXED VALIDATION BUG")
    print("=" * 70)
    
    # Set random seeds
    set_random_seeds(42)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"üñ•Ô∏è  Device: {device}")
    
    # Load CLIP model
    print(f"\nüì• Loading CLIP model...")
    clip_model, clip_preprocess = clip.load("ViT-B/32", device=device)
    clip_model.eval()
    for param in clip_model.parameters():
        param.requires_grad = False
    
    # Load data
    eegTrn, stimTrn, labelsTrn, eegVal, stimVal, labelsVal, eegTest, stimTest, labelsTest = load_crell_data()
    
    # Combine training and validation for CV
    all_eeg = np.concatenate([eegTrn, eegVal], axis=0)
    all_stim = np.concatenate([stimTrn, stimVal], axis=0)
    all_labels = np.concatenate([labelsTrn, labelsVal], axis=0)
    
    print(f"‚úÖ Dataset for CV: {len(all_eeg)} samples")
    
    # Initialize 5-fold CV
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    
    # Store results
    fold_results = []
    all_histories = []
    
    # Run CV
    for fold, (train_idx, val_idx) in enumerate(skf.split(all_eeg, all_labels)):
        print(f"\nüîÑ FOLD {fold + 1}/5")
        print("=" * 50)
        
        # Set seeds for this fold
        set_random_seeds(42 + fold)
        
        # Split data
        fold_eeg_train = all_eeg[train_idx]
        fold_stim_train = all_stim[train_idx]
        fold_labels_train = all_labels[train_idx]
        
        fold_eeg_val = all_eeg[val_idx]
        fold_stim_val = all_stim[val_idx]
        fold_labels_val = all_labels[val_idx]
        
        print(f"   Training: {len(fold_eeg_train)} samples")
        print(f"   Validation: {len(fold_eeg_val)} samples")
        
        # Create config and model
        config = Config()
        model = create_model(config, device)
        loss_fn = create_loss(config, device)
        optimizer, scheduler = create_optimizer_and_scheduler(model, config)
        
        # Training history
        history = {
            'train_losses': [],
            'train_accuracies': [],
            'val_losses': [],
            'val_accuracies': [],
            'learning_rates': []
        }
        
        best_val_accuracy = 0
        patience_counter = 0
        
        # Training loop
        for epoch in range(config.num_epochs):
            # Update learning rate
            current_lr = scheduler.step(epoch)
            
            # Training phase
            model.train()
            epoch_train_loss = 0
            epoch_train_accuracy = 0
            num_train_batches = 0
            
            # Create batches
            indices = np.arange(len(fold_eeg_train))
            np.random.shuffle(indices)
            
            for i in range(0, len(indices), config.batch_size):
                batch_indices = indices[i:i+config.batch_size]
                batch_eeg = fold_eeg_train[batch_indices]
                batch_stim = fold_stim_train[batch_indices]
                
                # Move to device
                batch_eeg = torch.FloatTensor(batch_eeg).to(device)
                
                # Process images
                processed_images = []
                for img in batch_stim:
                    if isinstance(img, np.ndarray):
                        if img.max() <= 1.0:
                            img = (img * 255).astype(np.uint8)
                        if len(img.shape) == 2:
                            img = np.stack([img, img, img], axis=-1)
                        from PIL import Image
                        img = Image.fromarray(img)
                    processed_img = clip_preprocess(img).unsqueeze(0)
                    processed_images.append(processed_img)
                processed_images = torch.cat(processed_images, dim=0).to(device)
                
                # Forward pass
                eeg_embeddings = model(batch_eeg)
                with torch.no_grad():
                    clip_embeddings = clip_model.encode_image(processed_images).float()
                
                # Compute loss
                loss, accuracy, temperature = loss_fn(eeg_embeddings, clip_embeddings)
                
                # Backward pass
                optimizer.zero_grad()
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=config.gradient_clip)
                optimizer.step()
                
                epoch_train_loss += loss.item()
                epoch_train_accuracy += accuracy.item()
                num_train_batches += 1
            
            # VALIDATION PHASE (EVERY EPOCH - FIXED!)
            val_loss, val_accuracy = evaluate_crell(
                model, fold_eeg_val, fold_stim_val, fold_labels_val,
                clip_model, clip_preprocess, device, "validation", config.batch_size
            )
            
            # Record metrics
            avg_train_loss = epoch_train_loss / num_train_batches
            avg_train_accuracy = epoch_train_accuracy / num_train_batches
            
            history['train_losses'].append(avg_train_loss)
            history['train_accuracies'].append(avg_train_accuracy)
            history['val_losses'].append(val_loss)
            history['val_accuracies'].append(val_accuracy)
            history['learning_rates'].append(current_lr)
            
            # Early stopping
            if val_accuracy > best_val_accuracy:
                best_val_accuracy = val_accuracy
                patience_counter = 0
                torch.save(model.state_dict(), f'fold_{fold+1}_best.pth')
            else:
                patience_counter += 1
            
            # Print progress
            if (epoch + 1) % 10 == 0:
                print(f"      Epoch {epoch+1}: Train Acc={avg_train_accuracy:.3f}, Val Acc={val_accuracy:.3f}")
            
            if patience_counter >= config.patience:
                print(f"      üõë Early stopping at epoch {epoch+1}")
                break
        
        # Store results
        fold_result = {
            'fold': fold + 1,
            'best_val_accuracy': best_val_accuracy,
            'epochs_trained': len(history['train_losses'])
        }
        
        fold_results.append(fold_result)
        all_histories.append(history)
        
        print(f"   ‚úÖ Fold {fold + 1}: Best Val Accuracy = {best_val_accuracy:.4f}")
    
    return fold_results, all_histories, eegTest, stimTest, labelsTest, clip_model, clip_preprocess, device

def plot_5fold_results(fold_results, all_histories):
    """Plot 5-fold CV results with LOSS and ACCURACY curves"""
    print("\nüìä Generating 5-fold CV plots with LOSS curves...")

    fig, axes = plt.subplots(3, 3, figsize=(20, 15))
    fig.suptitle('5-Fold Cross-Validation Results - Fixed Validation Bug (WITH LOSS CURVES)', fontsize=16)
    
    # Extract data
    val_accuracies = [result['best_val_accuracy'] for result in fold_results]
    mean_acc = np.mean(val_accuracies)
    std_acc = np.std(val_accuracies)
    
    # Plot 1: Validation accuracy by fold
    fold_numbers = [f"Fold {i+1}" for i in range(len(val_accuracies))]
    bars = axes[0, 0].bar(fold_numbers, val_accuracies, alpha=0.7, color='skyblue')
    axes[0, 0].axhline(y=mean_acc, color='red', linestyle='--', label=f'Mean: {mean_acc:.3f}')
    axes[0, 0].set_ylabel('Best Validation Accuracy')
    axes[0, 0].set_title('Best Validation Accuracy by Fold')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # Add value labels
    for bar, acc in zip(bars, val_accuracies):
        height = bar.get_height()
        axes[0, 0].annotate(f'{acc:.3f}',
                           xy=(bar.get_x() + bar.get_width() / 2, height),
                           xytext=(0, 3), textcoords="offset points",
                           ha='center', va='bottom', fontsize=10)
    
    # Plot 2: Validation ACCURACY curves for all folds
    colors = ['blue', 'red', 'green', 'orange', 'purple']
    for i, history in enumerate(all_histories):
        epochs = range(1, len(history['val_accuracies']) + 1)
        axes[0, 1].plot(epochs, history['val_accuracies'],
                       color=colors[i], alpha=0.7, label=f'Fold {i+1}')

    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Validation Accuracy')
    axes[0, 1].set_title('Validation ACCURACY Curves (All Folds)')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)

    # Plot 3: Validation LOSS curves for all folds
    for i, history in enumerate(all_histories):
        epochs = range(1, len(history['val_losses']) + 1)
        axes[0, 2].plot(epochs, history['val_losses'],
                       color=colors[i], alpha=0.7, label=f'Fold {i+1}')

    axes[0, 2].set_xlabel('Epoch')
    axes[0, 2].set_ylabel('Validation Loss')
    axes[0, 2].set_title('Validation LOSS Curves (All Folds)')
    axes[0, 2].legend()
    axes[0, 2].grid(True, alpha=0.3)
    
    # Plot 4: Training LOSS curves for all folds
    for i, history in enumerate(all_histories):
        epochs = range(1, len(history['train_losses']) + 1)
        axes[1, 0].plot(epochs, history['train_losses'],
                       color=colors[i], alpha=0.7, label=f'Fold {i+1}')

    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('Training Loss')
    axes[1, 0].set_title('Training LOSS Curves (All Folds)')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)
    
    # Plot 5: Training ACCURACY curves for all folds
    for i, history in enumerate(all_histories):
        epochs = range(1, len(history['train_accuracies']) + 1)
        axes[1, 1].plot(epochs, history['train_accuracies'],
                       color=colors[i], alpha=0.7, label=f'Fold {i+1}')

    axes[1, 1].set_xlabel('Epoch')
    axes[1, 1].set_ylabel('Training Accuracy')
    axes[1, 1].set_title('Training ACCURACY Curves (All Folds)')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)

    # Plot 6: Accuracy distribution
    axes[1, 2].hist(val_accuracies, bins=5, alpha=0.7, color='lightgreen', edgecolor='black')
    axes[1, 2].axvline(x=mean_acc, color='red', linestyle='--', label=f'Mean: {mean_acc:.3f}')
    axes[1, 2].axvline(x=0.1, color='gray', linestyle='--', label='Random: 0.1')
    axes[1, 2].set_xlabel('Accuracy')
    axes[1, 2].set_ylabel('Frequency')
    axes[1, 2].set_title('Accuracy Distribution')
    axes[1, 2].legend()
    axes[1, 2].grid(True, alpha=0.3)
    
    # Plot 7: Train vs Val Accuracy (Fold 1 example)
    if len(all_histories) > 0:
        first_fold_history = all_histories[0]
        epochs = range(1, len(first_fold_history['train_accuracies']) + 1)

        axes[2, 0].plot(epochs, first_fold_history['train_accuracies'],
                       label='Train Accuracy', alpha=0.8, color='blue')
        axes[2, 0].plot(epochs, first_fold_history['val_accuracies'],
                       label='Validation Accuracy', alpha=0.8, color='red')

    axes[2, 0].set_xlabel('Epoch')
    axes[2, 0].set_ylabel('Accuracy')
    axes[2, 0].set_title('Train vs Val Accuracy (Fold 1)')
    axes[2, 0].legend()
    axes[2, 0].grid(True, alpha=0.3)

    # Plot 8: Statistics summary
    stats_text = f"""5-Fold Cross-Validation Summary:

Validation Accuracy:
  Mean: {mean_acc:.4f} ¬± {std_acc:.4f}
  Range: {min(val_accuracies):.4f} - {max(val_accuracies):.4f}

Individual Fold Results:
  Fold 1: {val_accuracies[0]:.4f}
  Fold 2: {val_accuracies[1]:.4f}
  Fold 3: {val_accuracies[2]:.4f}
  Fold 4: {val_accuracies[3]:.4f}
  Fold 5: {val_accuracies[4]:.4f}

Performance vs Random (10%):
  Improvement: {mean_acc/0.1:.1f}x
  Percentage: {mean_acc*100:.1f}%

Validation Bug Status: ‚úÖ FIXED
  - Validation runs every epoch
  - LOSS curves now included
  - No more "flat" validation curves
  - Responsive early stopping"""

    axes[2, 1].text(0.05, 0.95, stats_text, transform=axes[2, 1].transAxes,
                   fontsize=9, verticalalignment='top', fontfamily='monospace')
    axes[2, 1].set_xlim(0, 1)
    axes[2, 1].set_ylim(0, 1)
    axes[2, 1].axis('off')
    axes[2, 1].set_title('CV Statistics Summary')

    # Plot 9: Epochs trained by fold
    epochs_trained = [result['epochs_trained'] for result in fold_results]
    bars9 = axes[2, 2].bar(fold_numbers, epochs_trained, alpha=0.7, color='orange')
    axes[2, 2].set_ylabel('Epochs Trained')
    axes[2, 2].set_title('Training Epochs by Fold')
    axes[2, 2].grid(True, alpha=0.3)

    # Add value labels
    for bar, epochs in zip(bars9, epochs_trained):
        height = bar.get_height()
        axes[2, 2].annotate(f'{epochs}',
                           xy=(bar.get_x() + bar.get_width() / 2, height),
                           xytext=(0, 3), textcoords="offset points",
                           ha='center', va='bottom', fontsize=10)
    
    plt.tight_layout()
    
    # Save plot
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    plot_filename = f'5fold_cv_fixed_results_{timestamp}.png'
    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"üìä 5-fold CV plot saved: {plot_filename}")
    
    return plot_filename, mean_acc, std_acc

def main():
    """Main function"""
    print("üöÄ 5-FOLD CV WITH FIXED VALIDATION BUG")
    print("=" * 60)
    
    start_time = datetime.now()
    
    # Run 5-fold CV
    fold_results, all_histories, eegTest, stimTest, labelsTest, clip_model, clip_preprocess, device = run_5fold_cv()
    
    # Plot results
    plot_filename, mean_acc, std_acc = plot_5fold_results(fold_results, all_histories)
    
    # Final summary
    end_time = datetime.now()
    duration = end_time - start_time
    
    print(f"\nüèÜ 5-FOLD CV COMPLETED!")
    print(f"   Duration: {duration}")
    print(f"   Mean Validation Accuracy: {mean_acc:.4f} ¬± {std_acc:.4f}")
    print(f"   Improvement over Random: {mean_acc/0.1:.1f}x")
    print(f"   Plot saved: {plot_filename}")
    print(f"   ‚úÖ Validation bug FIXED - No more flat curves!")

if __name__ == "__main__":
    main()
